{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knOigRU1UJ9Y"
   },
   "source": [
    "# Estimating Non-Mandatory Tour Frequency\n",
    "\n",
    "This notebook illustrates how to re-estimate a single model component for ActivitySim.  This process \n",
    "includes running ActivitySim in estimation mode to read household travel survey files and write out\n",
    "the estimation data bundles used in this notebook.  To review how to do so, please visit the other\n",
    "notebooks in this directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s53VwlPwtNnr",
    "outputId": "d1208b7a-c1f2-4b0b-c439-bf312fe12be0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import larch  # !conda install larch -c conda-forge # for estimation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import activitysim\n",
    "import datetime\n",
    "activitysim.__version__\n",
    "\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work in our `test` directory, where ActivitySim has saved the estimation data bundles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\ABM3_dev\\outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_coeffs(segment):\n",
    "    path = r'output\\estimation_data_bundle\\non_mandatory_tour_frequency'\n",
    "    spec = pd.read_csv(os.path.join(path, f'non_mandatory_tour_frequency_SPEC.csv'), comment='#')\n",
    "    # spec = pd.read_csv(os.path.join(r'C:\\ABM3_dev\\ABM\\src\\asim\\configs\\estimation', f'non_mandatory_tour_frequency.csv'), comment='#')\n",
    "    coefs = spec[segment].dropna()\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['coefficient_name'] = coefs\n",
    "    coefs_df.drop_duplicates(subset='coefficient_name', keep='first', inplace=True)\n",
    "    coefs_df['value'] = 0.0\n",
    "    coefs_df['constrain'] = 'F'\n",
    "    coefs_df.loc[coefs_df['coefficient_name'] == 'coef_unavailable', 'value'] = -999\n",
    "    coefs_df.loc[coefs_df['coefficient_name'] == 'coef_unavailable', 'constrain'] = 'T'\n",
    "    coefs_df.to_csv(os.path.join(path, segment, f'non_mandatory_tour_frequency_coefficients_{segment}.csv'), index=False)\n",
    "    # coefs_df.to_csv(os.path.join(r'C:\\ABM3_dev\\ABM\\src\\asim\\configs\\estimation', f'non_mandatory_tour_frequency_coefficients_{segment}.csv'), index=False)\n",
    "\n",
    "# write_coeffs('PTYPE_FULL')\n",
    "# write_coeffs('PTYPE_PART')\n",
    "# write_coeffs('PTYPE_UNIVERSITY')\n",
    "# write_coeffs('PTYPE_NONWORK')\n",
    "# write_coeffs('PTYPE_RETIRED')\n",
    "# write_coeffs('PTYPE_DRIVING')\n",
    "# write_coeffs('PTYPE_SCHOOL')\n",
    "# write_coeffs('PTYPE_PRESCHOOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tours = pd.read_csv(r\"C:\\ABM3_dev\\outputs\\output_estimation\\final_tours.csv\")\n",
    "# persons = pd.read_csv(r\"C:\\ABM3_dev\\run_data\\data_2z_series15\\override_persons.csv\")\n",
    "# tours = pd.read_csv(r\"C:\\ABM3_dev\\run_data\\data_2z_series15\\override_tours.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = pd.read_csv(r\"C:\\ABM3_dev\\outputs\\output\\final_persons.csv\")\n",
    "nm_purposes = ['_escort', '_shopping', '_othmaint', '_eatout', '_social', '_othdiscr']\n",
    "persons['total_indNM_tours'] = persons[nm_purposes].sum(axis=1)\n",
    "persons['age_binned'], bins = pd.cut(persons.age, bins=np.arange(0,91,2), retbins=True)\n",
    "persons.groupby(['age_binned']).total_indNM_tours.mean().plot(kind='bar', figsize=(12,5))\n",
    "# persons.age_binned.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and prep model for estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"nonmand_tour_freq\"\n",
    "\n",
    "from activitysim.estimation.larch import component_model\n",
    "# model, data = component_model(modelname, return_data=True, condense_parameters=False, num_chunks=10)\n",
    "model, data = component_model(modelname, return_data=True, condense_parameters=False, segment_subset=['PTYPE_SCHOOL', 'PTYPE_FULL', 'PTYPE_PRESCHOOL'], num_chunks=10)\n",
    "\n",
    "ptype_for_display = 'PTYPE_SCHOOL'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prototype model spec we are re-estimating has 210 rows for each person type, but the\n",
    "accompanying dataset is not large enough to successfully estimate anywhere near than many\n",
    "parameters. The `condense_parameters` option is activated here as a short cut to making\n",
    "a model that can be estimated with stable parameter results.  When activated, it merges\n",
    "parameters not only by name (i.e. when the same name appears twice it is the same parameter)\n",
    "but also by value, so that if the initial value of any two parameters is identical\n",
    "then they are treated as the same parameter.  Using \"condense_parameters\" in actual model\n",
    "estimation efforts is ill advised and may generate confusing or unexpected results.\n",
    "\n",
    "This component actually has a distinct choice model for each person type, so\n",
    "instead of a single model there's a `dict` of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review data loaded from the EDB\n",
    "\n",
    "We can review the data loaded as well, similarly there is seperate data \n",
    "for each person type."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.coefficients[ptype_for_display]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.spec[ptype_for_display]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chooser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.chooser_data[ptype_for_display]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_df = data.alt_values[ptype_for_display]\n",
    "alt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.chooser_data[ptype_for_display].copy()\n",
    "alts = pd.read_csv(r\"C:\\ABM3_dev\\outputs\\output\\estimation_data_bundle\\non_mandatory_tour_frequency\\non_mandatory_tour_frequency_alternatives.csv\", index_col=0)\n",
    "df = df.merge(alts, how='left', left_on='override_choice', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_counts = []\n",
    "for col in ['escort','shopping','othmaint','eatout','social','othdiscr','tot_tours', 'num_mandatory_tours', 'num_joint_tours']:\n",
    "    tmp = df[col].value_counts()\n",
    "    tour_counts.append(tmp)\n",
    "\n",
    "tour_counts = pd.concat(tour_counts, axis=1).fillna(0).astype(int)\n",
    "tour_counts.loc['Total'] = tour_counts.sum(axis=0)\n",
    "tour_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.tot_tours, df.income_segment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate\n",
    "\n",
    "With the model setup for estimation, the next step is to estimate the model coefficients.  Make sure to use a sufficiently large enough household sample and set of zones to avoid an over-specified model, which does not have a numerically stable likelihood maximizing solution.  The prototype model spec we are re-estimating has 210 rows for each person type, but the accompanying dataset is not large enough to successfully estimate anywhere near than many parameters, so a short cut is applied by having one parameter only per unique existing parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, m in model.items():\n",
    "    print(f\"Person type {k} has {len(m.utility_ca)} utility terms and {len(m.pf)} unique parameters.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future estimation work, parameters can be intelligently named and applied to match the model developer's desired structure (by using the same named parameter for multiple rows of the spec file).  If this is done, the \"short cut\" should be disabled by setting `condense_parameters=False` in the loading step above.\n",
    "\n",
    "Larch has a built-in estimation methods including BHHH, and also offers access to more advanced general purpose non-linear optimizers in the `scipy` package, including SLSQP, which allows for bounds and constraints on parameters.  BHHH is the default and typically runs faster, but does not follow constraints on parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, m in model.items():\n",
    "    # m.estimate(method='SLSQP')\n",
    "    m.estimate(method='BHHH', options={'maxiter':1500})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[ptype_for_display].parameter_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TojXWivZsx7M"
   },
   "source": [
    "# Output Estimation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activitysim.estimation.larch import update_coefficients\n",
    "for k, m in model.items():\n",
    "    result_dir = data.edb_directory/k/\"estimated\"\n",
    "    update_coefficients(\n",
    "        m, data.coefficients[k], result_dir,\n",
    "        output_file=f\"{modelname}_{k}_coefficients_revised_{datetime.datetime.now().strftime('%d_%m_%Y %H_%M_%S')}.csv\",\n",
    "        relabel_coef=data.relabel_coef.get(k),\n",
    "    );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the model estimation report, including coefficient t-statistic and log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, m in model.items():\n",
    "    result_dir = data.edb_directory/k/\"estimated\"\n",
    "    m.to_xlsx(\n",
    "        result_dir/f\"{modelname}_{k}_model_estimation_{datetime.datetime.now().strftime('%d_%m_%Y %H_%M_%S')}.xlsx\", \n",
    "        data_statistics=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "The final step is to either manually or automatically copy the `*_coefficients_revised.csv` file to the configs folder, rename it to `*_coefficients.csv`, and run ActivitySim in simulation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dir = data.edb_directory/'PTYPE_FULL'/\"estimated\"\n",
    "# pd.read_csv(result_dir/f\"{modelname}_PTYPE_FULL_coefficients_revised.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "asim_tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
